{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sys\n",
    "import os\n",
    "from datetime import timedelta\n",
    "\n",
    "from preprocess import read_and_preprocess_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in ./.venv/lib/python3.6/site-packages (0.24.1)\r\n",
      "Requirement already satisfied: pytz>=2011k in ./.venv/lib/python3.6/site-packages (from pandas) (2018.9)\r\n",
      "Requirement already satisfied: python-dateutil>=2.5.0 in ./.venv/lib/python3.6/site-packages (from pandas) (2.8.0)\r\n",
      "Requirement already satisfied: numpy>=1.12.0 in ./.venv/lib/python3.6/site-packages (from pandas) (1.16.1)\r\n",
      "Requirement already satisfied: six>=1.5 in ./.venv/lib/python3.6/site-packages (from python-dateutil>=2.5.0->pandas) (1.12.0)\r\n"
     ]
    }
   ],
   "source": [
    "!python -m pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_file = \"challenge/data/device_activations_small.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File challenge/data/device_activations_small.csv has 125 timesteps (hours)\n",
      "Feature batch:  (6, 20, 8)\n",
      "Label batch:  (6, 20, 6)\n"
     ]
    }
   ],
   "source": [
    "feature_batch, label_batch, device_list = read_and_preprocess_data(in_file)\n",
    "print(\"Feature batch: \", feature_batch.shape)\n",
    "print(\"Label batch: \", label_batch.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train len:  5\n",
      "(5, 20, 8)\n",
      "(1, 20, 8)\n"
     ]
    }
   ],
   "source": [
    "train_ratio = 0.9\n",
    "train_len = int(train_ratio * len(feature_batch))\n",
    "print(\"Train len: \", train_len)\n",
    "\n",
    "train_feature_batch = feature_batch[:train_len]\n",
    "test_feature_batch = feature_batch[train_len:]\n",
    "train_label_batch = label_batch[:train_len]\n",
    "test_label_batch = label_batch[train_len:]\n",
    "\n",
    "print(train_feature_batch.shape)\n",
    "print(test_feature_batch.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of positive outputs per device:  [0.21666667 0.23333333 0.15833333 0.13333333 0.18333333 0.05      ]\n"
     ]
    }
   ],
   "source": [
    "def calc_ratio_positive_outputs_per_device(labels):\n",
    "    ratio_per_device = np.sum(labels, axis=0) / labels.shape[0]\n",
    "    print(\"Percentage of positive outputs per device: \", ratio_per_device)\n",
    "    return np.array(ratio_per_device)\n",
    "ratio_positive_outputs_per_device = calc_ratio_positive_outputs_per_device(label_batch.reshape([-1, label_batch.shape[-1]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Dropout\n",
    "from keras.layers import LSTM\n",
    "from keras import objectives\n",
    "from keras import backend as K\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt\n",
    "\n",
    "from bayes_opt import BayesianOptimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "USE_WEIGHTED_LOSS = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create our own weighted loss to combat label imbalance\n",
    "def weighted_loss(y_true, y_pred):\n",
    "    out = -(y_true * K.log(y_pred + 1e-5) / ratio_positive_outputs_per_device + (1.0 - y_true) * K.log(1.0 - y_pred + 1e-5))\n",
    "    return K.mean(out, axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE=1\n",
    "def create_model(params):\n",
    "    n_outputs = len(device_list)\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(4, batch_input_shape=(params['batch_size'], None, feature_batch.shape[-1]), return_sequences=True, stateful=True))\n",
    "    model.add(Dropout(params['dropout']))\n",
    "    model.add(Dense(n_outputs, activation='sigmoid'))\n",
    "    model.compile(loss=weighted_loss if params['use_weighted_loss'] else 'binary_crossentropy', optimizer=params['optimizer'])\n",
    "    return model\n",
    "\n",
    "training_params = {'optimizer': 'adam', \n",
    "                   'use_weighted_loss': USE_WEIGHTED_LOSS,\n",
    "                   'batch_size': BATCH_SIZE,\n",
    "                   'dropout': 0.0,\n",
    "                   'epochs': 50}\n",
    "\n",
    "#model = create_model(training_params)\n",
    "#model.fit(train_feature_batch, train_label_batch, epochs=training_params['epochs'], batch_size=training_params['batch_size'], verbose=1, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_feature_batch_flattened = test_feature_batch.reshape([-1, *test_feature_batch.shape[-1:]])\n",
    "test_label_batch_flattened = test_label_batch.reshape([-1, *test_label_batch.shape[-1:]])\n",
    "test_feature_batch_expanded = test_feature_batch_flattened if len(test_feature_batch_flattened.shape) == 3 else np.expand_dims(test_feature_batch_flattened, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20, 1, 8)\n",
      "Train on 5 samples, validate on 20 samples\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 1s 162ms/step - loss: 1.2309 - val_loss: 2.0071\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 1.2222 - val_loss: 2.0016\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 1.2152 - val_loss: 1.9945\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 1.2083 - val_loss: 1.9872\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 1.2016 - val_loss: 1.9799\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 1.1951 - val_loss: 1.9729\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 1.1889 - val_loss: 1.9661\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 1.1829 - val_loss: 1.9595\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 1.1773 - val_loss: 1.9532\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 1.1720 - val_loss: 1.9470\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 1.1670 - val_loss: 1.9411\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 1.1622 - val_loss: 1.9353\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 1.1575 - val_loss: 1.9296\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 1.1530 - val_loss: 1.9240\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 1.1486 - val_loss: 1.9184\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 1.1442 - val_loss: 1.9128\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 1.1398 - val_loss: 1.9072\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 1.1355 - val_loss: 1.9016\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 1.1312 - val_loss: 1.8959\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 1.1268 - val_loss: 1.8903\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 1.1225 - val_loss: 1.8846\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 1.1182 - val_loss: 1.8789\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 1.1140 - val_loss: 1.8732\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 1.1097 - val_loss: 1.8675\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 1.1054 - val_loss: 1.8617\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 1.1012 - val_loss: 1.8560\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 1.0969 - val_loss: 1.8502\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 1.0925 - val_loss: 1.8442\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 1.0880 - val_loss: 1.8381\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 1.0835 - val_loss: 1.8317\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 1.0790 - val_loss: 1.8251\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 1.0743 - val_loss: 1.8183\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 1.0696 - val_loss: 1.8112\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 1.0647 - val_loss: 1.8038\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 1.0597 - val_loss: 1.7963\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 1.0546 - val_loss: 1.7884\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 1.0492 - val_loss: 1.7802\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 1.0439 - val_loss: 1.7718\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 1.0384 - val_loss: 1.7630\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 1.0328 - val_loss: 1.7540\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 1.0272 - val_loss: 1.7449\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 1.0216 - val_loss: 1.7356\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 1.0159 - val_loss: 1.7262\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 1.0102 - val_loss: 1.7168\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 1.0045 - val_loss: 1.7074\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 0.9988 - val_loss: 1.6982\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 0.9931 - val_loss: 1.6891\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 0.9876 - val_loss: 1.6803\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 0.9823 - val_loss: 1.6718\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 0.9772 - val_loss: 1.6637\n",
      "1.6637468039989471\n"
     ]
    }
   ],
   "source": [
    "def eval_model_params(params, train_X, train_Y, test_X, test_Y):\n",
    "    model = create_model(training_params)\n",
    "    history = model.fit(train_X, train_Y, validation_data=(test_X, np.expand_dims(test_Y, 1)), epochs=params['epochs'], batch_size=params['batch_size'], verbose=1, shuffle=False)\n",
    "    return model, history.history['val_loss'][-1]\n",
    "\n",
    "print(test_feature_batch_expanded.shape)\n",
    "model, result = eval_model_params(training_params, train_feature_batch, train_label_batch, test_feature_batch_expanded,test_label_batch_flattened)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20, 6)\n",
      "(20, 6)\n"
     ]
    }
   ],
   "source": [
    "predictions = model.predict(test_feature_batch_expanded, batch_size=1)\n",
    "predictions = np.squeeze(predictions)\n",
    "\n",
    "print(predictions.shape)\n",
    "print(test_label_batch_flattened.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy:  0.65\n",
      "Training accuracy per device::  [0.4  0.7  0.9  0.55 0.55 0.8 ]\n",
      "% of 1 prediction outputs 0.39166666666666666\n",
      "% of 1 label outputs 0.325\n"
     ]
    }
   ],
   "source": [
    "print(\"Training accuracy: \", np.sum(np.round(predictions) == test_label_batch_flattened) / predictions.size) \n",
    "print(\"Training accuracy per device:: \", np.sum(np.round(predictions) == test_label_batch_flattened, axis=0) / predictions.shape[0]) \n",
    "\n",
    "print(\"% of 1 prediction outputs\", np.sum(np.round(predictions)) / predictions.size) \n",
    "print(\"% of 1 label outputs\", np.sum(np.round(test_label_batch_flattened)) / test_label_batch_flattened.size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, in_file):\n",
    "    feature_batch, label_batch, device_list = read_and_preprocess_data(in_file)\n",
    "    predictions = np.concatenate(model.predict(feature_batch, batch_size=1), axis=0)\n",
    "    print(np.round(predictions))\n",
    "    print(np.concatenate(label_batch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File challenge/data/device_activations_small.csv has 125 timesteps (hours)\n",
      "[[0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 1. 0.]\n",
      " [1. 0. 0. 0. 1. 0.]\n",
      " [1. 1. 1. 0. 1. 0.]\n",
      " [1. 1. 0. 0. 1. 0.]\n",
      " [1. 1. 0. 0. 1. 0.]\n",
      " [1. 1. 0. 0. 1. 0.]\n",
      " [1. 1. 0. 0. 1. 0.]\n",
      " [1. 1. 0. 0. 1. 0.]\n",
      " [1. 1. 0. 0. 1. 0.]\n",
      " [1. 0. 0. 0. 1. 0.]\n",
      " [1. 0. 1. 0. 1. 0.]\n",
      " [1. 0. 1. 0. 1. 0.]\n",
      " [1. 0. 1. 0. 1. 0.]\n",
      " [1. 0. 0. 0. 1. 0.]\n",
      " [1. 0. 0. 0. 1. 0.]\n",
      " [1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 1.]\n",
      " [0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 1. 0. 0. 0.]\n",
      " [1. 1. 1. 0. 0. 0.]\n",
      " [1. 1. 1. 0. 0. 0.]\n",
      " [1. 1. 1. 0. 0. 0.]\n",
      " [1. 1. 1. 0. 0. 0.]\n",
      " [1. 1. 1. 0. 1. 0.]\n",
      " [1. 1. 1. 0. 1. 0.]\n",
      " [1. 1. 1. 0. 1. 0.]\n",
      " [1. 1. 1. 0. 1. 0.]\n",
      " [1. 1. 1. 0. 1. 0.]\n",
      " [1. 1. 1. 0. 1. 0.]\n",
      " [1. 1. 1. 0. 1. 0.]\n",
      " [1. 1. 1. 0. 1. 0.]\n",
      " [1. 1. 1. 0. 1. 0.]\n",
      " [1. 1. 1. 0. 1. 0.]\n",
      " [1. 1. 1. 0. 1. 0.]\n",
      " [1. 1. 1. 0. 0. 0.]\n",
      " [1. 1. 0. 0. 1. 0.]\n",
      " [1. 0. 1. 0. 0. 0.]\n",
      " [1. 0. 1. 0. 0. 0.]\n",
      " [1. 0. 1. 0. 0. 0.]\n",
      " [1. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 1. 0. 1. 0.]\n",
      " [1. 1. 1. 0. 1. 0.]\n",
      " [1. 1. 1. 0. 0. 0.]\n",
      " [1. 1. 1. 0. 0. 0.]\n",
      " [1. 1. 1. 0. 1. 0.]\n",
      " [1. 1. 1. 0. 1. 0.]\n",
      " [1. 1. 1. 0. 1. 0.]\n",
      " [1. 1. 1. 0. 1. 0.]\n",
      " [1. 1. 1. 0. 1. 0.]\n",
      " [1. 1. 1. 0. 1. 0.]\n",
      " [1. 1. 1. 0. 1. 0.]\n",
      " [1. 1. 1. 0. 1. 0.]\n",
      " [1. 1. 1. 0. 1. 0.]\n",
      " [1. 1. 1. 0. 1. 0.]\n",
      " [1. 1. 1. 0. 1. 0.]\n",
      " [1. 0. 0. 0. 1. 0.]\n",
      " [1. 0. 0. 0. 1. 0.]\n",
      " [1. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 0. 0.]]\n",
      "[[0 0 0 0 0 0]\n",
      " [1 0 0 0 0 0]\n",
      " [1 0 1 0 1 0]\n",
      " [1 1 1 1 1 0]\n",
      " [1 1 0 0 0 0]\n",
      " [1 1 0 0 0 0]\n",
      " [1 1 0 0 0 0]\n",
      " [1 1 0 0 0 0]\n",
      " [1 1 0 0 0 0]\n",
      " [1 1 0 0 0 0]\n",
      " [1 1 0 0 0 0]\n",
      " [1 0 0 0 0 0]\n",
      " [0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0]\n",
      " [0 1 0 0 0 0]\n",
      " [0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0]\n",
      " [1 0 0 0 0 0]\n",
      " [1 0 0 0 0 0]\n",
      " [1 1 0 0 0 0]\n",
      " [1 1 0 0 0 0]\n",
      " [1 1 0 0 0 0]\n",
      " [1 1 0 0 0 0]\n",
      " [1 1 1 1 1 0]\n",
      " [1 1 1 1 1 0]\n",
      " [1 1 1 1 1 1]\n",
      " [1 1 1 1 1 1]\n",
      " [1 1 1 1 1 1]\n",
      " [1 1 1 0 1 0]\n",
      " [0 1 0 0 1 0]\n",
      " [0 1 0 0 0 0]\n",
      " [0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0]\n",
      " [0 0 0 0 1 0]\n",
      " [0 0 1 0 1 1]\n",
      " [0 0 1 1 1 1]\n",
      " [0 0 1 1 1 0]\n",
      " [0 0 1 1 1 0]\n",
      " [0 0 1 1 1 0]\n",
      " [0 0 1 1 1 0]\n",
      " [0 0 1 1 1 0]\n",
      " [0 1 1 1 1 0]\n",
      " [1 1 1 1 1 0]\n",
      " [1 1 1 1 1 0]\n",
      " [1 1 1 1 1 1]\n",
      " [0 1 0 0 1 0]\n",
      " [0 1 0 0 0 0]\n",
      " [0 1 0 0 0 0]\n",
      " [0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "test(model, in_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_next_24h(model, in_file):\n",
    "    feature_batch, label_batch, device_list = read_and_preprocess_data(in_file, batch=False)\n",
    "    print(feature_batch.shape)\n",
    "    print(label_batch.shape)\n",
    "    predictions = np.concatenate(model.predict(feature_batch, batch_size=1), axis=0)\n",
    "    \n",
    "    all_predictions = []\n",
    "    \n",
    "    last_features = feature_batch[-1, -1]\n",
    "    last_predictions = tmp_prediction = predictions[-1]\n",
    "    \n",
    "    tmp_features = np.array(last_features)\n",
    "    tmp_features = np.concatenate([tmp_features[:2], last_predictions])\n",
    "    for i in range(24):\n",
    "        print(tmp_features)\n",
    "        #print(tmp_prediction)\n",
    "        tmp_prediction = model.predict(np.reshape(tmp_features, [1, 1, len(tmp_features)]))\n",
    "        tmp_features = np.concatenate([tmp_features[:2], tmp_prediction[0, 0]])\n",
    "        \n",
    "        # Increment time features\n",
    "        if tmp_features[1] == 23:\n",
    "            tmp_features[0] = (tmp_features[0] + 1) % 7\n",
    "        tmp_features[1] = (tmp_features[1] + 1) % 24\n",
    "        all_predictions += [tmp_prediction]\n",
    "        \n",
    "    return np.round(np.concatenate(all_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File challenge/data/device_activations_smaller.csv has 101 timesteps (hours)\n",
      "(1, 101, 8)\n",
      "(1, 101, 6)\n",
      "[1.         8.         0.77860647 0.68049347 0.67319858 0.48214319\n",
      " 0.50550455 0.47616789]\n",
      "[1.         9.         0.76215994 0.67184883 0.61911422 0.46631485\n",
      " 0.550753   0.45250982]\n",
      "[ 1.         10.          0.77873981  0.69111705  0.62019163  0.46910295\n",
      "  0.55646479  0.44288379]\n",
      "[ 1.         11.          0.78449249  0.70032597  0.62080002  0.47093201\n",
      "  0.55876052  0.44107732]\n",
      "[ 1.         12.          0.78311628  0.7005477   0.62543631  0.47316068\n",
      "  0.55331606  0.44604701]\n",
      "[ 1.         13.          0.7778784   0.69623584  0.62634516  0.47462222\n",
      "  0.54749453  0.45005   ]\n",
      "[ 1.         14.          0.76835316  0.68731016  0.62264574  0.47530323\n",
      "  0.54161876  0.45259631]\n",
      "[ 1.         15.          0.75672191  0.67616898  0.61688381  0.47636336\n",
      "  0.53408718  0.45377833]\n",
      "[ 1.         16.          0.74262661  0.66273099  0.60850155  0.47766167\n",
      "  0.52539051  0.45347774]\n",
      "[ 1.         17.          0.72611541  0.64687282  0.59775496  0.4790332\n",
      "  0.5157485   0.45175701]\n",
      "[ 1.         18.          0.70755154  0.62864977  0.58535248  0.48026797\n",
      "  0.50545955  0.44890639]\n",
      "[ 1.         19.          0.68757284  0.60844231  0.572218    0.48119488\n",
      "  0.49488959  0.44535828]\n",
      "[ 1.         20.          0.66694307  0.58692658  0.55922109  0.481736\n",
      "  0.48440132  0.44156393]\n",
      "[ 1.         21.          0.64540344  0.56609213  0.54615653  0.48181078\n",
      "  0.47576109  0.43918118]\n",
      "[ 1.         22.          0.62364727  0.54622358  0.53365642  0.48146483\n",
      "  0.46873441  0.43813279]\n",
      "[ 1.         23.          0.60266834  0.52718645  0.52239233  0.48085281\n",
      "  0.46249792  0.43774706]\n",
      "[2.         0.         0.58271748 0.50937951 0.51230866 0.48008391\n",
      " 0.45704812 0.43799224]\n",
      "[2.         1.         0.48862875 0.51933318 0.46120465 0.48072207\n",
      " 0.49128875 0.49801946]\n",
      "[2.         2.         0.47861245 0.52173465 0.42833909 0.47923762\n",
      " 0.50572681 0.48134819]\n",
      "[2.         3.         0.5031209  0.52801579 0.41802576 0.47296226\n",
      " 0.52233762 0.45560497]\n",
      "[2.         4.         0.55850756 0.54156178 0.44700074 0.46433252\n",
      " 0.53489423 0.44065943]\n",
      "[2.         5.         0.62708193 0.56891441 0.50391096 0.4589555\n",
      " 0.54159755 0.44189224]\n",
      "[2.         6.         0.68476677 0.60262686 0.55719191 0.45835352\n",
      " 0.54498154 0.44866881]\n",
      "[2.         7.         0.71938509 0.62840503 0.5870654  0.45885554\n",
      " 0.5496102  0.45209548]\n"
     ]
    }
   ],
   "source": [
    "test_file = \"challenge/data/device_activations_smaller.csv\"\n",
    "future_predictions = predict_next_24h(model, test_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File challenge/data/device_activations_small.csv has 125 timesteps (hours)\n",
      "(125, 6)\n",
      "(24, 6)\n",
      "[[1 1 1 0 1 0]\n",
      " [1 1 1 0 1 0]\n",
      " [1 1 1 0 1 0]\n",
      " [1 1 1 0 1 0]\n",
      " [1 1 1 0 1 0]\n",
      " [1 1 1 0 1 0]\n",
      " [1 1 1 0 1 0]\n",
      " [1 1 1 0 1 0]\n",
      " [1 1 1 0 1 0]\n",
      " [1 1 1 0 1 0]\n",
      " [1 1 1 0 0 0]\n",
      " [1 1 1 0 0 0]\n",
      " [1 1 1 0 0 0]\n",
      " [1 1 1 0 0 0]\n",
      " [1 1 1 0 0 0]\n",
      " [1 1 1 0 0 0]\n",
      " [0 1 0 0 0 0]\n",
      " [0 1 0 0 1 0]\n",
      " [1 1 0 0 1 0]\n",
      " [1 1 0 0 1 0]\n",
      " [1 1 1 0 1 0]\n",
      " [1 1 1 0 1 0]\n",
      " [1 1 1 0 1 0]\n",
      " [1 1 1 0 1 0]]\n",
      "[[0 0 1 1 1 0]\n",
      " [0 0 1 1 1 0]\n",
      " [0 0 1 1 1 0]\n",
      " [0 0 1 1 1 0]\n",
      " [0 1 1 1 1 0]\n",
      " [1 1 1 1 1 0]\n",
      " [1 1 1 1 1 0]\n",
      " [1 1 1 1 1 1]\n",
      " [0 1 0 0 1 0]\n",
      " [0 1 0 0 0 0]\n",
      " [0 1 0 0 0 0]\n",
      " [0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0]\n",
      " [1 0 0 0 1 0]\n",
      " [1 1 1 0 1 0]\n",
      " [1 1 1 1 1 1]\n",
      " [1 1 1 1 1 1]]\n"
     ]
    }
   ],
   "source": [
    "label_file = \"challenge/data/device_activations_small.csv\"\n",
    "model.reset_states()\n",
    "feature_batch, label_batch, device_list = read_and_preprocess_data(label_file, batch=False)\n",
    "label_batch = label_batch.squeeze()\n",
    "print(label_batch.shape)\n",
    "print(future_predictions.shape)\n",
    "future_predictions = np.squeeze(future_predictions.astype(np.int64))\n",
    "print(future_predictions)\n",
    "print(label_batch[-24:])\n",
    "future_labels = label_batch[-24:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(24, 6)\n",
      "(24, 6)\n",
      "Test accuracy:  0.6180555555555556\n",
      "Test accuracy per device::  [0.375      0.41666667 0.625      0.58333333 0.83333333 0.875     ]\n"
     ]
    }
   ],
   "source": [
    "print(future_predictions.shape)\n",
    "print(future_labels.shape)\n",
    "\n",
    "print(\"Test accuracy: \", np.sum(np.round(future_predictions) == future_labels) / future_labels.size) \n",
    "print(\"Test accuracy per device:: \", np.sum(np.round(future_predictions) == future_labels, axis=0) / future_labels.shape[0]) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
