{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sys\n",
    "import os\n",
    "from datetime import timedelta\n",
    "\n",
    "from preprocess import read_and_preprocess_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in ./.venv/lib/python3.6/site-packages (0.24.1)\n",
      "Requirement already satisfied: numpy>=1.12.0 in ./.venv/lib/python3.6/site-packages (from pandas) (1.16.1)\n",
      "Requirement already satisfied: pytz>=2011k in ./.venv/lib/python3.6/site-packages (from pandas) (2018.9)\n",
      "Requirement already satisfied: python-dateutil>=2.5.0 in ./.venv/lib/python3.6/site-packages (from pandas) (2.8.0)\n",
      "Requirement already satisfied: six>=1.5 in ./.venv/lib/python3.6/site-packages (from python-dateutil>=2.5.0->pandas) (1.12.0)\n"
     ]
    }
   ],
   "source": [
    "!python -m pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_file = \"challenge/data/device_activations.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_devices =  6\n",
      "Feature batch:  (6, 20, 8)\n",
      "Label batch:  (6, 20, 6)\n"
     ]
    }
   ],
   "source": [
    "feature_batch, label_batch, device_list = read_and_preprocess_data(in_file)\n",
    "print(\"Feature batch: \", feature_batch.shape)\n",
    "print(\"Label batch: \", label_batch.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train len:  4\n",
      "(4, 20, 8)\n",
      "(2, 20, 8)\n"
     ]
    }
   ],
   "source": [
    "train_ratio = 0.8\n",
    "train_len = int(train_ratio * len(feature_batch))\n",
    "print(\"Train len: \", train_len)\n",
    "\n",
    "train_feature_batch = feature_batch[:train_len]\n",
    "test_feature_batch = feature_batch[train_len:]\n",
    "train_label_batch = label_batch[:train_len]\n",
    "test_label_batch = label_batch[train_len:]\n",
    "\n",
    "print(train_feature_batch.shape)\n",
    "print(test_feature_batch.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of positive outputs per device:  [0.21666667 0.23333333 0.15833333 0.13333333 0.18333333 0.05      ]\n"
     ]
    }
   ],
   "source": [
    "def calc_ratio_positive_outputs_per_device(labels):\n",
    "    ratio_per_device = np.sum(labels, axis=0) / labels.shape[0]\n",
    "    print(\"Percentage of positive outputs per device: \", ratio_per_device)\n",
    "    return np.array(ratio_per_device)\n",
    "ratio_positive_outputs_per_device = calc_ratio_positive_outputs_per_device(label_batch.reshape([-1, label_batch.shape[-1]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Dropout\n",
    "from keras.layers import LSTM\n",
    "from keras import objectives\n",
    "from keras import backend as K\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt\n",
    "\n",
    "from bayes_opt import BayesianOptimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "USE_WEIGHTED_LOSS = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create our own weighted loss to combat label imbalance\n",
    "def weighted_loss(y_true, y_pred):\n",
    "    out = -(y_true * K.log(y_pred + 1e-5) / ratio_positive_outputs_per_device + (1.0 - y_true) * K.log(1.0 - y_pred + 1e-5))\n",
    "    return K.mean(out, axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE=1\n",
    "def create_model(params):\n",
    "    n_outputs = len(device_list)\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(32, batch_input_shape=(params['batch_size'], None, feature_batch.shape[-1]), return_sequences=True, stateful=True))\n",
    "    model.add(Dropout(params['dropout']))\n",
    "    model.add(Dense(n_outputs, activation='sigmoid'))\n",
    "    model.compile(loss=weighted_loss if params['use_weighted_loss'] else 'binary_crossentropy', optimizer=params['optimizer'])\n",
    "    return model\n",
    "\n",
    "training_params = {'optimizer': 'adam', \n",
    "                   'use_weighted_loss': USE_WEIGHTED_LOSS,\n",
    "                   'batch_size': BATCH_SIZE,\n",
    "                   'dropout': 0.0,\n",
    "                   'epochs': 500}\n",
    "\n",
    "#model = create_model(training_params)\n",
    "#model.fit(train_feature_batch, train_label_batch, epochs=training_params['epochs'], batch_size=training_params['batch_size'], verbose=1, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_feature_batch_flattened = test_feature_batch.reshape([-1, *test_feature_batch.shape[-1:]])\n",
    "test_label_batch_flattened = test_label_batch.reshape([-1, *test_label_batch.shape[-1:]])\n",
    "test_feature_batch_expanded = test_feature_batch_flattened if len(test_feature_batch_flattened.shape) == 3 else np.expand_dims(test_feature_batch_flattened, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(40, 1, 8)\n",
      "Train on 4 samples, validate on 40 samples\n",
      "Epoch 1/50\n",
      "4/4 [==============================] - 1s 197ms/step - loss: 0.9593 - val_loss: 2.3019\n",
      "Epoch 2/50\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 0.9161 - val_loss: 2.3567\n",
      "Epoch 3/50\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 0.8834 - val_loss: 2.4150\n",
      "Epoch 4/50\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 0.8546 - val_loss: 2.4738\n",
      "Epoch 5/50\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 0.8288 - val_loss: 2.5312\n",
      "Epoch 6/50\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 0.8054 - val_loss: 2.5859\n",
      "Epoch 7/50\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 0.7841 - val_loss: 2.6364\n",
      "Epoch 8/50\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 0.7645 - val_loss: 2.6804\n",
      "Epoch 9/50\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 0.7464 - val_loss: 2.7166\n",
      "Epoch 10/50\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 0.7293 - val_loss: 2.7445\n",
      "Epoch 11/50\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 0.7132 - val_loss: 2.7667\n",
      "Epoch 12/50\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 0.6980 - val_loss: 2.7879\n",
      "Epoch 13/50\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 0.6833 - val_loss: 2.8104\n",
      "Epoch 14/50\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 0.6690 - val_loss: 2.8264\n",
      "Epoch 15/50\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 0.6547 - val_loss: 2.8270\n",
      "Epoch 16/50\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 0.6394 - val_loss: 2.8141\n",
      "Epoch 17/50\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 0.6224 - val_loss: 2.8340\n",
      "Epoch 18/50\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 0.6059 - val_loss: 2.8702\n",
      "Epoch 19/50\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 0.5902 - val_loss: 2.8541\n",
      "Epoch 20/50\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 0.5740 - val_loss: 2.8436\n",
      "Epoch 21/50\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 0.5611 - val_loss: 2.7903\n",
      "Epoch 22/50\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 0.5461 - val_loss: 2.7461\n",
      "Epoch 23/50\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 0.5300 - val_loss: 2.7325\n",
      "Epoch 24/50\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 0.5159 - val_loss: 2.7001\n",
      "Epoch 25/50\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 0.5001 - val_loss: 2.6326\n",
      "Epoch 26/50\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 0.4864 - val_loss: 2.6940\n",
      "Epoch 27/50\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 0.4818 - val_loss: 2.7289\n",
      "Epoch 28/50\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 0.4720 - val_loss: 2.6137\n",
      "Epoch 29/50\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 0.4547 - val_loss: 2.5516\n",
      "Epoch 30/50\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 0.4430 - val_loss: 2.5915\n",
      "Epoch 31/50\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 0.4369 - val_loss: 2.6192\n",
      "Epoch 32/50\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 0.4263 - val_loss: 2.5061\n",
      "Epoch 33/50\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 0.4106 - val_loss: 2.4117\n",
      "Epoch 34/50\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 0.4004 - val_loss: 2.4859\n",
      "Epoch 35/50\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 0.4052 - val_loss: 2.5800\n",
      "Epoch 36/50\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 0.3987 - val_loss: 2.4255\n",
      "Epoch 37/50\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 0.3856 - val_loss: 2.3266\n",
      "Epoch 38/50\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 0.3763 - val_loss: 2.2921\n",
      "Epoch 39/50\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 0.3640 - val_loss: 2.2981\n",
      "Epoch 40/50\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 0.3595 - val_loss: 2.2756\n",
      "Epoch 41/50\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 0.3461 - val_loss: 2.1763\n",
      "Epoch 42/50\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 0.3398 - val_loss: 2.1993\n",
      "Epoch 43/50\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 0.3321 - val_loss: 2.2365\n",
      "Epoch 44/50\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 0.3289 - val_loss: 2.1905\n",
      "Epoch 45/50\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 0.3195 - val_loss: 2.1377\n",
      "Epoch 46/50\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 0.3093 - val_loss: 2.1221\n",
      "Epoch 47/50\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 0.3017 - val_loss: 2.1362\n",
      "Epoch 48/50\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 0.2946 - val_loss: 2.1401\n",
      "Epoch 49/50\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 0.2867 - val_loss: 2.1332\n",
      "Epoch 50/50\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 0.2804 - val_loss: 2.1450\n",
      "2.1450266569852827\n"
     ]
    }
   ],
   "source": [
    "def eval_model_params(params, train_X, train_Y, test_X, test_Y):\n",
    "    model = create_model(training_params)\n",
    "    history = model.fit(train_X, train_Y, validation_data=(test_X, np.expand_dims(test_Y, 1)), epochs=params['epochs'], batch_size=params['batch_size'], verbose=1, shuffle=False)\n",
    "    predictions = model.predict(test_X, batch_size=1)\n",
    "    return model, history.history['val_loss'][-1]\n",
    "\n",
    "print(test_feature_batch_expanded.shape)\n",
    "model, result = eval_model_params(training_params, train_feature_batch, train_label_batch, test_feature_batch_expanded,test_label_batch_flattened)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(40, 1, 8)\n",
      "(40, 6)\n",
      "(40, 6)\n"
     ]
    }
   ],
   "source": [
    "print(test_feature_batch_expanded.shape)\n",
    "predictions = model.predict(test_feature_batch_expanded, batch_size=1)[:, 0, :]\n",
    "#print(np.round(predictions, 1))\n",
    "\n",
    "print(predictions.shape)\n",
    "print(test_label_batch_flattened.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy:  0.5583333333333333\n",
      "Training accuracy per device::  [0.2   0.55  0.525 0.7   0.525 0.85 ]\n",
      "% of 1 prediction outputs 0.5958333333333333\n",
      "% of 1 label outputs 0.32083333333333336\n"
     ]
    }
   ],
   "source": [
    "print(\"Training accuracy: \", np.sum(np.round(predictions) == test_label_batch_flattened) / predictions.size) \n",
    "print(\"Training accuracy per device:: \", np.sum(np.round(predictions) == test_label_batch_flattened, axis=0) / predictions.shape[0]) \n",
    "\n",
    "print(\"% of 1 prediction outputs\", np.sum(np.round(predictions)) / predictions.size) \n",
    "print(\"% of 1 label outputs\", np.sum(np.round(test_label_batch_flattened)) / test_label_batch_flattened.size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(40, 1, 8)\n",
      "(1, 40, 6)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "In a stateful network, you should only pass inputs with a number of samples that can be divided by the batch size. Found: 40 samples",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-31fb51532fb5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_feature_batch_expanded\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand_dims\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_label_batch_flattened\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand_dims\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_feature_batch_flattened\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand_dims\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_label_batch_flattened\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/hodschallenge/.venv/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(self, x, y, batch_size, verbose, sample_weight, steps)\u001b[0m\n\u001b[1;32m   1100\u001b[0m             \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1101\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1102\u001b[0;31m             batch_size=batch_size)\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Prepare inputs, delegate logic to `test_loop`.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_uses_dynamic_learning_phase\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/hodschallenge/.venv/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[0;34m(self, x, y, sample_weight, class_weight, check_array_lengths, batch_size)\u001b[0m\n\u001b[1;32m    820\u001b[0m                                  \u001b[0;34m'a number of samples that can be '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    821\u001b[0m                                  \u001b[0;34m'divided by the batch size. Found: '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 822\u001b[0;31m                                  str(x[0].shape[0]) + ' samples')\n\u001b[0m\u001b[1;32m    823\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    824\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: In a stateful network, you should only pass inputs with a number of samples that can be divided by the batch size. Found: 40 samples"
     ]
    }
   ],
   "source": [
    "print(test_feature_batch_expanded.shape)\n",
    "print(np.expand_dims(test_label_batch_flattened, 0).shape)\n",
    "model.evaluate(np.expand_dims(test_feature_batch_flattened, 1), np.expand_dims(test_label_batch_flattened, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, in_file):\n",
    "    feature_batch, label_batch, device_list = read_and_preprocess_data(in_file)\n",
    "    print(feature_batch.shape)\n",
    "    print()\n",
    "    predictions = np.concatenate(model.predict(feature_batch, batch_size=1), axis=0)\n",
    "    print(np.round(predictions))\n",
    "    print(np.concatenate(label_batch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_devices =  6\n",
      "(6, 20, 8)\n",
      "\n",
      "[[1. 1. 1. 1. 1. 0.]\n",
      " [1. 1. 1. 1. 1. 0.]\n",
      " [1. 1. 1. 1. 1. 0.]\n",
      " [1. 1. 1. 1. 1. 0.]\n",
      " [1. 1. 1. 1. 0. 0.]\n",
      " [1. 1. 0. 1. 0. 0.]\n",
      " [1. 1. 0. 1. 0. 0.]\n",
      " [1. 1. 0. 0. 0. 0.]\n",
      " [1. 1. 0. 0. 0. 0.]\n",
      " [1. 1. 0. 0. 0. 0.]\n",
      " [1. 1. 0. 0. 0. 0.]\n",
      " [1. 1. 0. 0. 0. 0.]\n",
      " [1. 1. 0. 0. 0. 0.]\n",
      " [1. 1. 0. 0. 0. 0.]\n",
      " [1. 1. 0. 0. 0. 0.]\n",
      " [1. 1. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0.]\n",
      " [1. 1. 0. 0. 0. 0.]\n",
      " [1. 1. 0. 0. 0. 0.]\n",
      " [1. 1. 0. 0. 0. 0.]\n",
      " [1. 1. 0. 0. 0. 0.]\n",
      " [1. 1. 0. 1. 1. 0.]\n",
      " [1. 1. 1. 1. 1. 0.]\n",
      " [1. 1. 1. 1. 1. 0.]\n",
      " [1. 1. 1. 1. 1. 0.]\n",
      " [1. 1. 1. 1. 1. 0.]\n",
      " [1. 1. 1. 1. 1. 0.]\n",
      " [1. 1. 1. 1. 1. 0.]\n",
      " [1. 1. 1. 1. 1. 0.]\n",
      " [1. 1. 1. 1. 1. 0.]\n",
      " [1. 1. 1. 1. 1. 0.]\n",
      " [1. 1. 1. 0. 1. 0.]\n",
      " [1. 0. 0. 0. 1. 0.]\n",
      " [1. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 1. 0. 0. 0.]\n",
      " [1. 1. 1. 1. 1. 0.]\n",
      " [1. 1. 1. 1. 1. 0.]\n",
      " [1. 1. 1. 1. 1. 0.]\n",
      " [1. 1. 1. 1. 1. 0.]\n",
      " [1. 1. 1. 1. 1. 0.]\n",
      " [1. 1. 1. 1. 1. 0.]\n",
      " [1. 1. 1. 1. 1. 0.]\n",
      " [1. 1. 1. 1. 1. 0.]\n",
      " [1. 1. 1. 1. 1. 0.]\n",
      " [1. 1. 1. 1. 1. 0.]\n",
      " [1. 1. 0. 1. 0. 0.]\n",
      " [1. 1. 0. 1. 0. 0.]\n",
      " [1. 1. 0. 0. 0. 0.]\n",
      " [1. 1. 0. 0. 0. 0.]\n",
      " [1. 1. 0. 0. 0. 0.]\n",
      " [1. 1. 0. 0. 0. 0.]\n",
      " [1. 1. 0. 0. 0. 0.]\n",
      " [1. 1. 0. 0. 0. 0.]\n",
      " [1. 1. 0. 0. 0. 0.]\n",
      " [1. 1. 0. 0. 0. 0.]\n",
      " [1. 1. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 1. 0. 0. 0.]\n",
      " [1. 1. 1. 0. 0. 0.]\n",
      " [1. 1. 1. 0. 0. 0.]\n",
      " [1. 1. 1. 1. 1. 0.]]\n",
      "[[0 0 0 0 0 0]\n",
      " [1 0 0 0 0 0]\n",
      " [1 0 1 0 1 0]\n",
      " [1 1 1 1 1 0]\n",
      " [1 1 0 0 0 0]\n",
      " [1 1 0 0 0 0]\n",
      " [1 1 0 0 0 0]\n",
      " [1 1 0 0 0 0]\n",
      " [1 1 0 0 0 0]\n",
      " [1 1 0 0 0 0]\n",
      " [1 1 0 0 0 0]\n",
      " [1 0 0 0 0 0]\n",
      " [0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0]\n",
      " [0 1 0 0 0 0]\n",
      " [0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0]\n",
      " [1 0 0 0 0 0]\n",
      " [1 0 0 0 0 0]\n",
      " [1 1 0 0 0 0]\n",
      " [1 1 0 0 0 0]\n",
      " [1 1 0 0 0 0]\n",
      " [1 1 0 0 0 0]\n",
      " [1 1 1 1 1 0]\n",
      " [1 1 1 1 1 0]\n",
      " [1 1 1 1 1 1]\n",
      " [1 1 1 1 1 1]\n",
      " [1 1 1 1 1 1]\n",
      " [1 1 1 0 1 0]\n",
      " [0 1 0 0 1 0]\n",
      " [0 1 0 0 0 0]\n",
      " [0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0]\n",
      " [0 0 0 0 1 0]\n",
      " [0 0 1 0 1 1]\n",
      " [0 0 1 1 1 1]\n",
      " [0 0 1 1 1 0]\n",
      " [0 0 1 1 1 0]\n",
      " [0 0 1 1 1 0]\n",
      " [0 0 1 1 1 0]\n",
      " [0 0 1 1 1 0]\n",
      " [0 1 1 1 1 0]\n",
      " [1 1 1 1 1 0]\n",
      " [1 1 1 1 1 0]\n",
      " [1 1 1 1 1 1]\n",
      " [0 1 0 0 1 0]\n",
      " [0 1 0 0 0 0]\n",
      " [0 1 0 0 0 0]\n",
      " [0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "test(model, in_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_next_24h(model, in_file):\n",
    "    feature_batch, label_batch, device_list = read_and_preprocess_data(in_file, batch=False)\n",
    "    print(feature_batch.shape)\n",
    "    predictions = np.concatenate(model.predict(feature_batch, batch_size=1), axis=0)\n",
    "    \n",
    "    all_predictions = []\n",
    "    \n",
    "    last_features = feature_batch[-1, -1]\n",
    "    last_predictions = tmp_prediction = predictions[-1]\n",
    "    \n",
    "    tmp_features = np.array(last_features)\n",
    "    tmp_features = np.concatenate([tmp_features[:2], last_predictions])\n",
    "    for i in range(24):\n",
    "        print(tmp_features)\n",
    "        #print(tmp_prediction)\n",
    "        tmp_prediction = model.predict(np.reshape(tmp_features, [1, 1, len(tmp_features)]))\n",
    "        tmp_features = np.concatenate([tmp_features[:2], tmp_prediction[0, 0]])\n",
    "        \n",
    "        # Increment time features\n",
    "        if tmp_features[1] == 23:\n",
    "            tmp_features[0] = (tmp_features[0] + 1) % 7\n",
    "        tmp_features[1] = (tmp_features[1] + 1) % 24\n",
    "        all_predictions += [tmp_prediction]\n",
    "        \n",
    "    return np.round(np.concatenate(all_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_devices =  6\n",
      "(126, 8)\n",
      "(1, 125, 8)\n",
      "(1, 125, 8)\n",
      "[2.         8.         0.91190243 0.88213348 0.59595782 0.7012167\n",
      " 0.62391579 0.29530293]\n",
      "[2.         9.         0.91102493 0.89612156 0.55159348 0.68520343\n",
      " 0.57022959 0.29278094]\n",
      "[ 2.         10.          0.90740961  0.90560627  0.48719582  0.66345352\n",
      "  0.51060152  0.2800338 ]\n",
      "[ 2.         11.          0.90172833  0.90972906  0.42170647  0.62879521\n",
      "  0.44854927  0.25896266]\n",
      "[ 2.         12.          0.89519471  0.90910804  0.3573429   0.58177882\n",
      "  0.39012527  0.23086329]\n",
      "[ 2.         13.          0.88727748  0.90266097  0.30780712  0.5283283\n",
      "  0.34144971  0.19592878]\n",
      "[ 2.         14.          0.87746763  0.89020646  0.26501456  0.46236995\n",
      "  0.30031362  0.16245091]\n",
      "[ 2.         15.          0.86451501  0.87246168  0.22832969  0.39337948\n",
      "  0.26824841  0.13266958]\n",
      "[ 2.         16.          0.84727764  0.84849769  0.19901721  0.32680047\n",
      "  0.24366005  0.10763361]\n",
      "[ 2.         17.          0.82445002  0.81692815  0.17837429  0.26699057\n",
      "  0.22538742  0.0878184 ]\n",
      "[ 2.         18.          0.79362017  0.77811307  0.16800626  0.21592605\n",
      "  0.21199629  0.0739223 ]\n",
      "[ 2.         19.          0.75575852  0.72951889  0.16589592  0.17681101\n",
      "  0.20241362  0.06461624]\n",
      "[ 2.         20.          0.7125749   0.67104673  0.1703319   0.1490113\n",
      "  0.1959001   0.05843014]\n",
      "[ 2.         21.          0.66644865  0.60620022  0.17898272  0.12884645\n",
      "  0.19399247  0.05450522]\n",
      "[ 2.         22.          0.62358487  0.53939408  0.19179827  0.11462713\n",
      "  0.20026264  0.05254376]\n",
      "[ 2.         23.          0.58971381  0.47346261  0.21404324  0.1063209\n",
      "  0.22193712  0.05249877]\n",
      "[3.         0.         0.56770629 0.4088634  0.25203004 0.10377162\n",
      " 0.26638791 0.05460143]\n",
      "[3.         1.         0.69453019 0.52373087 0.47126535 0.24366996\n",
      " 0.27672741 0.08455604]\n",
      "[3.         2.         0.73716164 0.60016543 0.47970292 0.31448084\n",
      " 0.31288034 0.09318735]\n",
      "[3.         3.         0.78097248 0.67054349 0.49163207 0.40023673\n",
      " 0.35459119 0.11300819]\n",
      "[3.         4.         0.82355279 0.74278086 0.49603087 0.4793154\n",
      " 0.39517727 0.14039437]\n",
      "[3.         5.         0.85706383 0.80650121 0.48073918 0.53070623\n",
      " 0.41395143 0.16743816]\n",
      "[3.         6.         0.87787294 0.85425508 0.44755441 0.55496913\n",
      " 0.40330288 0.1857028 ]\n",
      "[3.         7.         0.88795102 0.88466716 0.40480629 0.55983508\n",
      " 0.37074211 0.19174741]\n"
     ]
    }
   ],
   "source": [
    "test_file = \"challenge/data/device_activations_smaller.csv\"\n",
    "future_predictions = predict_next_24h(model, in_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_devices =  6\n",
      "(126, 8)\n",
      "(1, 125, 8)\n",
      "a\n",
      "(24, 1, 6)\n",
      "[[1 1 1 1 1 0]\n",
      " [1 1 0 1 1 0]\n",
      " [1 1 0 1 0 0]\n",
      " [1 1 0 1 0 0]\n",
      " [1 1 0 1 0 0]\n",
      " [1 1 0 0 0 0]\n",
      " [1 1 0 0 0 0]\n",
      " [1 1 0 0 0 0]\n",
      " [1 1 0 0 0 0]\n",
      " [1 1 0 0 0 0]\n",
      " [1 1 0 0 0 0]\n",
      " [1 1 0 0 0 0]\n",
      " [1 1 0 0 0 0]\n",
      " [1 1 0 0 0 0]\n",
      " [1 0 0 0 0 0]\n",
      " [1 0 0 0 0 0]\n",
      " [1 1 0 0 0 0]\n",
      " [1 1 0 0 0 0]\n",
      " [1 1 0 0 0 0]\n",
      " [1 1 0 0 0 0]\n",
      " [1 1 0 1 0 0]\n",
      " [1 1 0 1 0 0]\n",
      " [1 1 0 1 0 0]\n",
      " [1 1 0 1 0 0]]\n",
      "[[0 0 1 1 1 0]\n",
      " [0 0 1 1 1 0]\n",
      " [0 0 1 1 1 0]\n",
      " [0 0 1 1 1 0]\n",
      " [0 1 1 1 1 0]\n",
      " [1 1 1 1 1 0]\n",
      " [1 1 1 1 1 0]\n",
      " [1 1 1 1 1 1]\n",
      " [0 1 0 0 1 0]\n",
      " [0 1 0 0 0 0]\n",
      " [0 1 0 0 0 0]\n",
      " [0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0]\n",
      " [1 0 0 0 1 0]\n",
      " [1 1 1 0 1 0]\n",
      " [1 1 1 1 1 1]\n",
      " [1 1 1 1 1 1]]\n"
     ]
    }
   ],
   "source": [
    "label_file = \"challenge/data/device_activations_small.csv\"\n",
    "model.reset_states()\n",
    "feature_batch, label_batch, device_list = read_and_preprocess_data(label_file, batch=False)\n",
    "print(\"a\")\n",
    "print(future_predictions.shape)\n",
    "future_predictions = future_predictions.astype(np.int64)[:, 0]\n",
    "print(future_predictions)\n",
    "print(label_batch[0, -24:])\n",
    "future_labels = label_batch[0, -24:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy:  0.5972222222222222\n",
      "Test accuracy per device::  [0.29166667 0.5        0.58333333 0.79166667 0.54166667 0.875     ]\n",
      "% of 1 prediction outputs 0.5958333333333333\n",
      "% of 1 label outputs 0.32083333333333336\n"
     ]
    }
   ],
   "source": [
    "print(\"Test accuracy: \", np.sum(np.round(future_predictions) == future_labels) / future_labels.size) \n",
    "print(\"Test accuracy per device:: \", np.sum(np.round(future_predictions) == future_labels, axis=0) / future_labels.shape[0]) \n",
    "\n",
    "print(\"% of 1 prediction outputs\", np.sum(np.round(predictions)) / predictions.size) \n",
    "print(\"% of 1 label outputs\", np.sum(np.round(test_label_batch_flattened)) / test_label_batch_flattened.size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
