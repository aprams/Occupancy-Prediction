{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sys\n",
    "import os\n",
    "from datetime import timedelta\n",
    "\n",
    "from preprocess import read_and_preprocess_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in ./.venv/lib/python3.6/site-packages (0.24.1)\r\n",
      "Requirement already satisfied: python-dateutil>=2.5.0 in ./.venv/lib/python3.6/site-packages (from pandas) (2.8.0)\r\n",
      "Requirement already satisfied: pytz>=2011k in ./.venv/lib/python3.6/site-packages (from pandas) (2018.9)\r\n",
      "Requirement already satisfied: numpy>=1.12.0 in ./.venv/lib/python3.6/site-packages (from pandas) (1.16.1)\r\n",
      "Requirement already satisfied: six>=1.5 in ./.venv/lib/python3.6/site-packages (from python-dateutil>=2.5.0->pandas) (1.12.0)\r\n"
     ]
    }
   ],
   "source": [
    "!python -m pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_file = \"challenge/data/device_activations_medium.csv\"\n",
    "BATCH_SIZE = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File challenge/data/device_activations_medium.csv has 316 timesteps (hours)\n",
      "initial features shape:  (316, 8)\n",
      "Full sequence length:  240\n",
      "Sequence 0 has start index 0 and end index 240\n",
      "(240, 8)\n",
      "Sequence 1 has start index 4 and end index 244\n",
      "(240, 8)\n",
      "Sequence 2 has start index 8 and end index 248\n",
      "(240, 8)\n",
      "Sequence 3 has start index 12 and end index 252\n",
      "(240, 8)\n",
      "Sequence 4 has start index 16 and end index 256\n",
      "(240, 8)\n",
      "Sequence 5 has start index 20 and end index 260\n",
      "(240, 8)\n",
      "Sequence 6 has start index 24 and end index 264\n",
      "(240, 8)\n",
      "Sequence 7 has start index 28 and end index 268\n",
      "(240, 8)\n",
      "Sequence 8 has start index 32 and end index 272\n",
      "(240, 8)\n",
      "Sequence 9 has start index 36 and end index 276\n",
      "(240, 8)\n",
      "Sequence 10 has start index 40 and end index 280\n",
      "(240, 8)\n",
      "Sequence 11 has start index 44 and end index 284\n",
      "(240, 8)\n",
      "Sequence 12 has start index 48 and end index 288\n",
      "(240, 8)\n",
      "Sequence 13 has start index 52 and end index 292\n",
      "(240, 8)\n",
      "Sequence 14 has start index 56 and end index 296\n",
      "(240, 8)\n",
      "Sequence 15 has start index 60 and end index 300\n",
      "(240, 8)\n",
      "Features sequences shape:  (16, 12, 20, 8)\n",
      "Labels sequences shape:  (16, 12, 20, 6)\n",
      "Feature batch:  (192, 20, 8)\n",
      "Label batch:  (192, 20, 6)\n"
     ]
    }
   ],
   "source": [
    "feature_batch, label_batch, device_list = read_and_preprocess_data(in_file, batch_size=BATCH_SIZE)\n",
    "print(\"Feature batch: \", feature_batch.shape)\n",
    "print(\"Label batch: \", label_batch.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train len:  160\n",
      "(160, 20, 8)\n",
      "(32, 20, 8)\n"
     ]
    }
   ],
   "source": [
    "train_ratio = 0.9\n",
    "train_len = int(train_ratio * len(feature_batch) // BATCH_SIZE) * BATCH_SIZE\n",
    "print(\"Train len: \", train_len)\n",
    "\n",
    "train_feature_batch = feature_batch[:train_len]\n",
    "test_feature_batch = feature_batch[train_len:]\n",
    "train_label_batch = label_batch[:train_len]\n",
    "test_label_batch = label_batch[train_len:]\n",
    "\n",
    "print(train_feature_batch.shape)\n",
    "print(test_feature_batch.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of positive outputs per device:  [0.26848958 0.19713542 0.24817708 0.22890625 0.31614583 0.1       ]\n"
     ]
    }
   ],
   "source": [
    "def calc_ratio_positive_outputs_per_device(labels):\n",
    "    ratio_per_device = np.sum(labels, axis=0) / labels.shape[0]\n",
    "    print(\"Percentage of positive outputs per device: \", ratio_per_device)\n",
    "    return np.array(ratio_per_device)\n",
    "ratio_positive_outputs_per_device = calc_ratio_positive_outputs_per_device(label_batch.reshape([-1, label_batch.shape[-1]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.layers import Dense, Activation, Dropout\n",
    "from keras.layers import LSTM\n",
    "from keras import objectives\n",
    "from keras import backend as K\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt\n",
    "\n",
    "from bayes_opt import BayesianOptimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "USE_WEIGHTED_LOSS = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create our own weighted loss to combat label imbalance\n",
    "def weighted_loss(y_true, y_pred):\n",
    "    out = -(y_true * K.log(y_pred + 1e-5) / ratio_positive_outputs_per_device + (1.0 - y_true) * K.log(1.0 - y_pred + 1e-5))\n",
    "    return K.mean(out, axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(params):\n",
    "    n_outputs = len(device_list)\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(8, batch_input_shape=(params['batch_size'], None, feature_batch.shape[-1]), return_sequences=True, stateful=True))\n",
    "    model.add(Dropout(params['dropout']))\n",
    "    model.add(Dense(n_outputs, activation='sigmoid'))\n",
    "    model.compile(loss=weighted_loss if params['use_weighted_loss'] else 'binary_crossentropy', optimizer=params['optimizer'])\n",
    "    return model\n",
    "\n",
    "training_params = {'optimizer': 'adam', \n",
    "                   'use_weighted_loss': USE_WEIGHTED_LOSS,\n",
    "                   'batch_size': BATCH_SIZE,\n",
    "                   'dropout': 0.0,\n",
    "                   'epochs': 25}\n",
    "\n",
    "#model = create_model(training_params)\n",
    "#model.fit(train_feature_batch, train_label_batch, epochs=training_params['epochs'], batch_size=training_params['batch_size'], verbose=1, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_feature_batch_flattened = test_feature_batch.reshape([-1, *test_feature_batch.shape[-1:]])\n",
    "test_label_batch_flattened = test_label_batch.reshape([-1, *test_label_batch.shape[-1:]])\n",
    "test_feature_batch_expanded = test_feature_batch_flattened if len(test_feature_batch_flattened.shape) == 3 else np.expand_dims(test_feature_batch_flattened, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 160 samples, validate on 32 samples\n",
      "Epoch 1/25\n",
      "160/160 [==============================] - 1s 6ms/step - loss: 1.2328 - val_loss: 1.2065\n",
      "Epoch 2/25\n",
      "160/160 [==============================] - 0s 858us/step - loss: 1.2259 - val_loss: 1.1979\n",
      "Epoch 3/25\n",
      "160/160 [==============================] - 0s 877us/step - loss: 1.2181 - val_loss: 1.1894\n",
      "Epoch 4/25\n",
      "160/160 [==============================] - 0s 892us/step - loss: 1.2105 - val_loss: 1.1809\n",
      "Epoch 5/25\n",
      "160/160 [==============================] - 0s 898us/step - loss: 1.2030 - val_loss: 1.1726\n",
      "Epoch 6/25\n",
      "160/160 [==============================] - 0s 899us/step - loss: 1.1953 - val_loss: 1.1643\n",
      "Epoch 7/25\n",
      "160/160 [==============================] - 0s 941us/step - loss: 1.1874 - val_loss: 1.1558\n",
      "Epoch 8/25\n",
      "160/160 [==============================] - 0s 942us/step - loss: 1.1788 - val_loss: 1.1469\n",
      "Epoch 9/25\n",
      "160/160 [==============================] - 0s 915us/step - loss: 1.1694 - val_loss: 1.1376\n",
      "Epoch 10/25\n",
      "160/160 [==============================] - 0s 965us/step - loss: 1.1596 - val_loss: 1.1281\n",
      "Epoch 11/25\n",
      "160/160 [==============================] - 0s 929us/step - loss: 1.1496 - val_loss: 1.1186\n",
      "Epoch 12/25\n",
      "160/160 [==============================] - 0s 992us/step - loss: 1.1394 - val_loss: 1.1091\n",
      "Epoch 13/25\n",
      "160/160 [==============================] - 0s 990us/step - loss: 1.1289 - val_loss: 1.0992\n",
      "Epoch 14/25\n",
      "160/160 [==============================] - 0s 878us/step - loss: 1.1178 - val_loss: 1.0888\n",
      "Epoch 15/25\n",
      "160/160 [==============================] - 0s 951us/step - loss: 1.1059 - val_loss: 1.0772\n",
      "Epoch 16/25\n",
      "160/160 [==============================] - 0s 959us/step - loss: 1.0928 - val_loss: 1.0638\n",
      "Epoch 17/25\n",
      "160/160 [==============================] - 0s 951us/step - loss: 1.0780 - val_loss: 1.0478\n",
      "Epoch 18/25\n",
      "160/160 [==============================] - 0s 985us/step - loss: 1.0612 - val_loss: 1.0290\n",
      "Epoch 19/25\n",
      "160/160 [==============================] - 0s 990us/step - loss: 1.0423 - val_loss: 1.0071\n",
      "Epoch 20/25\n",
      "160/160 [==============================] - 0s 969us/step - loss: 1.0214 - val_loss: 0.9807\n",
      "Epoch 21/25\n",
      "160/160 [==============================] - 0s 974us/step - loss: 0.9990 - val_loss: 0.9546\n",
      "Epoch 22/25\n",
      "160/160 [==============================] - 0s 962us/step - loss: 0.9779 - val_loss: 0.9342\n",
      "Epoch 23/25\n",
      "160/160 [==============================] - 0s 980us/step - loss: 0.9592 - val_loss: 0.9170\n",
      "Epoch 24/25\n",
      "160/160 [==============================] - 0s 943us/step - loss: 0.9418 - val_loss: 0.9007\n",
      "Epoch 25/25\n",
      "160/160 [==============================] - 0s 974us/step - loss: 0.9249 - val_loss: 0.8844\n",
      "0.8844384253025055\n"
     ]
    }
   ],
   "source": [
    "def eval_model_params(params, train_X, train_Y, test_X, test_Y):\n",
    "    model = create_model(training_params)\n",
    "    history = model.fit(train_X, train_Y, validation_data=(test_X, test_Y), epochs=params['epochs'], batch_size=params['batch_size'], verbose=1, shuffle=False)\n",
    "    return model, history.history['val_loss'][-1]\n",
    "\n",
    "model, result = eval_model_params(training_params, train_feature_batch, train_label_batch, test_feature_batch, test_label_batch)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(640, 6)\n",
      "(640, 6)\n"
     ]
    }
   ],
   "source": [
    "predictions = model.predict(test_feature_batch_expanded, batch_size=BATCH_SIZE)\n",
    "predictions = np.squeeze(predictions)\n",
    "\n",
    "print(predictions.shape)\n",
    "print(test_label_batch_flattened.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val accuracy:  0.434375\n",
      "Val accuracy per device::  [0.3765625 0.35      0.4578125 0.665625  0.3953125 0.3609375]\n",
      "% of 1 prediction outputs 0.7942708333333334\n",
      "% of 1 label outputs 0.23125\n"
     ]
    }
   ],
   "source": [
    "print(\"Val accuracy: \", np.sum(np.round(predictions) == test_label_batch_flattened) / predictions.size) \n",
    "print(\"Val accuracy per device:: \", np.sum(np.round(predictions) == test_label_batch_flattened, axis=0) / predictions.shape[0]) \n",
    "\n",
    "print(\"% of 1 prediction outputs\", np.sum(np.round(predictions)) / predictions.size) \n",
    "print(\"% of 1 label outputs\", np.sum(np.round(test_label_batch_flattened)) / test_label_batch_flattened.size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras.losses\n",
    "keras.losses.weighted_loss = weighted_loss\n",
    "\n",
    "test_model_params = dict(training_params)\n",
    "test_model_params['batch_size'] = 1\n",
    "\n",
    "#test_model = load_model(\"model.h5)\n",
    "test_model = create_model(test_model_params)\n",
    "test_model.load_weights('model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, in_file):\n",
    "    test_features, test_labels, device_list = read_and_preprocess_data(in_file, batch_size=1)\n",
    "    print(feature_batch.shape)\n",
    "    print(label_batch.shape)\n",
    "    predictions = np.concatenate(model.predict(feature_batch, batch_size=1), axis=0)\n",
    "    print(np.round(predictions))\n",
    "    print(np.concatenate(label_batch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File challenge/data/device_activations_medium.csv has 316 timesteps (hours)\n",
      "(192, 20, 8)\n",
      "(192, 20, 6)\n",
      "[[1. 0. 0. 0. 1. 1.]\n",
      " [1. 0. 0. 0. 1. 0.]\n",
      " [1. 1. 1. 0. 1. 0.]\n",
      " ...\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]]\n",
      "[[0 0 0 0 0 0]\n",
      " [1 0 0 0 0 0]\n",
      " [1 0 1 0 1 0]\n",
      " ...\n",
      " [1 0 0 0 0 0]\n",
      " [1 0 1 1 1 0]\n",
      " [1 0 1 1 1 0]]\n"
     ]
    }
   ],
   "source": [
    "test(test_model, in_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_next_24h(model, in_file):\n",
    "    feature_batch, label_batch, device_list = read_and_preprocess_data(in_file, batch_size=1)\n",
    "    print(feature_batch.shape)\n",
    "    print(label_batch.shape)\n",
    "    predictions = np.concatenate(model.predict(feature_batch, batch_size=1), axis=0)\n",
    "    \n",
    "    all_predictions = []\n",
    "    \n",
    "    last_features = feature_batch[-1, -1]\n",
    "    last_predictions = tmp_prediction = predictions[-1]\n",
    "    \n",
    "    tmp_features = np.array(last_features)\n",
    "    tmp_features = np.concatenate([tmp_features[:2], last_predictions])\n",
    "    for i in range(24):\n",
    "        print(tmp_features)\n",
    "        #print(tmp_prediction)\n",
    "        tmp_prediction = model.predict(np.reshape(tmp_features, [1, 1, len(tmp_features)]))\n",
    "        tmp_features = np.concatenate([tmp_features[:2], tmp_prediction[0, 0]])\n",
    "        \n",
    "        # Increment time features\n",
    "        if tmp_features[1] == 23:\n",
    "            tmp_features[0] = (tmp_features[0] + 1) % 7\n",
    "        tmp_features[1] = (tmp_features[1] + 1) % 24\n",
    "        all_predictions += [tmp_prediction]\n",
    "        \n",
    "    return np.round(np.concatenate(all_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File challenge/data/device_activations_smaller.csv has 101 timesteps (hours)\n",
      "(1, 101, 8)\n",
      "(1, 101, 6)\n",
      "[1.         8.         0.55332178 0.69843179 0.76699567 0.70377851\n",
      " 0.76194447 0.6802941 ]\n",
      "[1.         9.         0.57329249 0.73396206 0.78556907 0.73067397\n",
      " 0.7740925  0.70703465]\n",
      "[ 1.         10.          0.57637829  0.74729389  0.79342312  0.74379557\n",
      "  0.7784043   0.7187081 ]\n",
      "[ 1.         11.          0.57657576  0.75145435  0.79409629  0.74891824\n",
      "  0.777798    0.72364622]\n",
      "[ 1.         12.          0.57666266  0.75197977  0.79097897  0.75042915\n",
      "  0.77467412  0.72589231]\n",
      "[ 1.         13.          0.5773052   0.75040632  0.78513825  0.75009733\n",
      "  0.76955068  0.72684294]\n",
      "[ 1.         14.          0.58032584  0.74715793  0.77442849  0.74717814\n",
      "  0.76080287  0.72820425]\n",
      "[ 1.         15.          0.58450484  0.74134254  0.75970739  0.74305487\n",
      "  0.7490412   0.72863734]\n",
      "[ 1.         16.          0.58981699  0.73251843  0.74017614  0.73743552\n",
      "  0.73362011  0.72811431]\n",
      "[ 1.         17.          0.59450442  0.72073972  0.7179724   0.7311784\n",
      "  0.71618706  0.72532183]\n",
      "[ 1.         18.          0.59888053  0.70769989  0.6934278   0.72304845\n",
      "  0.69722438  0.72120076]\n",
      "[ 1.         19.          0.60219067  0.69513142  0.66925669  0.7132957\n",
      "  0.67892569  0.71558386]\n",
      "[ 1.         20.          0.60425723  0.68420649  0.64735365  0.70214373\n",
      "  0.66258085  0.70866573]\n",
      "[ 1.         21.          0.60528713  0.6752193   0.62825352  0.68973672\n",
      "  0.648431    0.70063227]\n",
      "[ 1.         22.          0.60560179  0.66788751  0.61158812  0.67611575\n",
      "  0.63608903  0.69157219]\n",
      "[ 1.         23.          0.60546345  0.66177702  0.59673327  0.66129035\n",
      "  0.62503624  0.68150598]\n",
      "[2.         0.         0.60499364 0.65661073 0.5833028  0.64531326\n",
      " 0.61497748 0.67044622]\n",
      "[2.         1.         0.60608292 0.59282064 0.62958038 0.58845454\n",
      " 0.65730697 0.55944604]\n",
      "[2.         2.         0.57837588 0.63709682 0.67688608 0.59563488\n",
      " 0.69592667 0.56251264]\n",
      "[2.         3.         0.56911033 0.68484831 0.72982323 0.63125932\n",
      " 0.73606128 0.59645057]\n",
      "[2.         4.         0.57637715 0.71579355 0.76359683 0.67131579\n",
      " 0.76026708 0.64009523]\n",
      "[2.         5.         0.58350372 0.73245883 0.78232777 0.70054996\n",
      " 0.7739712  0.67337102]\n",
      "[2.         6.         0.58642119 0.74166095 0.79289073 0.72041398\n",
      " 0.78196853 0.69505483]\n",
      "[2.         7.         0.58623844 0.74750775 0.79944879 0.73466307\n",
      " 0.78713036 0.70992398]\n"
     ]
    }
   ],
   "source": [
    "test_file = \"challenge/data/device_activations_smaller.csv\"\n",
    "future_predictions = predict_next_24h(test_model, test_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File challenge/data/device_activations_small.csv has 125 timesteps (hours)\n",
      "(125, 6)\n",
      "(24, 1, 6)\n",
      "[[1 1 1 1 1 1]\n",
      " [1 1 1 1 1 1]\n",
      " [1 1 1 1 1 1]\n",
      " [1 1 1 1 1 1]\n",
      " [1 1 1 1 1 1]\n",
      " [1 1 1 1 1 1]\n",
      " [1 1 1 1 1 1]\n",
      " [1 1 1 1 1 1]\n",
      " [1 1 1 1 1 1]\n",
      " [1 1 1 1 1 1]\n",
      " [1 1 1 1 1 1]\n",
      " [1 1 1 1 1 1]\n",
      " [1 1 1 1 1 1]\n",
      " [1 1 1 1 1 1]\n",
      " [1 1 1 1 1 1]\n",
      " [1 1 1 1 1 1]\n",
      " [1 1 1 1 1 1]\n",
      " [1 1 1 1 1 1]\n",
      " [1 1 1 1 1 1]\n",
      " [1 1 1 1 1 1]\n",
      " [1 1 1 1 1 1]\n",
      " [1 1 1 1 1 1]\n",
      " [1 1 1 1 1 1]\n",
      " [1 1 1 1 1 1]]\n",
      "[[0 0 1 1 1 0]\n",
      " [0 0 1 1 1 0]\n",
      " [0 0 1 1 1 0]\n",
      " [0 0 1 1 1 0]\n",
      " [0 1 1 1 1 0]\n",
      " [1 1 1 1 1 0]\n",
      " [1 1 1 1 1 0]\n",
      " [1 1 1 1 1 1]\n",
      " [0 1 0 0 1 0]\n",
      " [0 1 0 0 0 0]\n",
      " [0 1 0 0 0 0]\n",
      " [0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0]\n",
      " [1 0 0 0 1 0]\n",
      " [1 1 1 0 1 0]\n",
      " [1 1 1 1 1 1]\n",
      " [1 1 1 1 1 1]]\n"
     ]
    }
   ],
   "source": [
    "label_file = \"challenge/data/device_activations_small.csv\"\n",
    "test_model.reset_states()\n",
    "feature_batch, label_batch, device_list = read_and_preprocess_data(label_file, batch_size=1)\n",
    "label_batch = label_batch.squeeze()\n",
    "print(label_batch.shape)\n",
    "print(future_predictions.shape)\n",
    "future_predictions = np.squeeze(future_predictions.astype(np.int64))\n",
    "print(future_predictions)\n",
    "print(label_batch[-24:])\n",
    "future_labels = label_batch[-24:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(24, 6)\n",
      "(24, 6)\n",
      "Test accuracy:  0.375\n",
      "Test accuracy per device::  [0.29166667 0.41666667 0.45833333 0.41666667 0.54166667 0.125     ]\n"
     ]
    }
   ],
   "source": [
    "print(future_predictions.shape)\n",
    "print(future_labels.shape)\n",
    "\n",
    "print(\"Test accuracy: \", np.sum(np.round(future_predictions) == future_labels) / future_labels.size) \n",
    "print(\"Test accuracy per device:: \", np.sum(np.round(future_predictions) == future_labels, axis=0) / future_labels.shape[0]) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sandbox\n",
    "a = np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
