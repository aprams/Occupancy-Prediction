{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Occupancy Timeseries Forecast\n",
    "## Predict occupancies for future hours from a known history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import itertools\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sys\n",
    "import os\n",
    "from datetime import timedelta\n",
    "\n",
    "from preprocess import read_and_preprocess_data\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.layers import Dense, Activation, Dropout\n",
    "from keras.layers import LSTM\n",
    "from keras.regularizers import l2\n",
    "from keras import objectives\n",
    "from keras import backend as K\n",
    "from keras import optimizers\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt\n",
    "\n",
    "from bayes_opt import BayesianOptimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_file = \"challenge/data/device_activations_train.csv\"\n",
    "val_in_file = \"challenge/data/device_activations_val.csv\"\n",
    "test_in_file = \"challenge/data/device_activations_test.csv\"\n",
    "device_list=['device_1', 'device_2', 'device_3', 'device_4', 'device_5', 'device_6', 'device_7']\n",
    "BATCH_SIZE = 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load & preprocess data\n",
    "Load data from csv files, expects different files for training, validation and test (to be specified in the cell above)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hours in data:  1014\n",
      "File challenge/data/device_activations_train.csv has 1013 timesteps (hours) until now\n",
      "initial features shape:  (1013, 16)\n",
      "Full sequence length:  900\n",
      "Sequence 0 has start index 0 and end index 900\n",
      "(900, 16)\n",
      "Sequence 1 has start index 20 and end index 920\n",
      "(900, 16)\n",
      "Sequence 2 has start index 40 and end index 940\n",
      "(900, 16)\n",
      "Sequence 3 has start index 60 and end index 960\n",
      "(900, 16)\n",
      "Features sequences shape:  (4, 9, 100, 16)\n",
      "Labels sequences shape:  (4, 9, 100, 7)\n",
      "Feature batch shape:  (36, 100, 16)\n",
      "Label batch shape:  (36, 100, 7)\n"
     ]
    }
   ],
   "source": [
    "feature_batch, label_batch, device_list, mean_occupancies = read_and_preprocess_data(in_file, batch_size=BATCH_SIZE, device_list=device_list, sequence_start_shift=20)\n",
    "print(\"Feature batch shape: \", feature_batch.shape)\n",
    "print(\"Label batch shape: \", label_batch.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mean occupancy visualization per hour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.         0.         0.         0.         0.         0.\n",
      " 0.04395604 0.1487743  0.31445478 0.36517329 0.31107354 0.40236686\n",
      " 0.28064243 0.43956044 0.44632291 0.51394759 0.44294167 0.16906171\n",
      " 0.03381234 0.03043111 0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.04057481 0.21301775 0.30431107 0.36855452 0.40912933 0.41251057\n",
      " 0.26373626 0.40912933 0.45984784 0.51394759 0.4057481  0.16568047\n",
      " 0.04057481 0.0202874  0.04057481 0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.07100592 0.34826712 0.44632291 0.44294167 0.34150465 0.3956044\n",
      " 0.38884193 0.48689772 0.51394759 0.54775993 0.44632291 0.29416737\n",
      " 0.06762468 0.00676247 0.         0.00338123 0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.05748098 0.30769231 0.49027895 0.5545224  0.52747253 0.44970414\n",
      " 0.45646661 0.52409129 0.55114117 0.534235   0.37531699 0.22316145\n",
      " 0.08453085 0.02704987 0.00676247 0.         0.         0.\n",
      " 0.         0.         0.         0.         0.00338123 0.\n",
      " 0.06086221 0.2874049  0.40912933 0.36517329 0.22992392 0.24344886\n",
      " 0.2671175  0.40912933 0.38546069 0.31783601 0.18258664 0.06424345\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.00338123 0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.00338123 0.0202874  0.00676247 0.\n",
      " 0.         0.         0.         0.         0.         0.00338123\n",
      " 0.01690617 0.         0.         0.         0.00338123 0.\n",
      " 0.         0.         0.00338123 0.         0.         0.        ]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "mean_occupancy_per_hour = mean_occupancies.to_numpy().reshape([168, 7]).sum(axis=1) / 7\n",
    "labels = range(len(mean_occupancy_per_hour))\n",
    "print(mean_occupancy_per_hour)\n",
    "plt.bar(labels, mean_occupancy_per_hour, color=\"blue\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hours in data:  288\n",
      "File challenge/data/device_activations_val.csv has 287 timesteps (hours) until now\n",
      "Hours in data:  176\n",
      "File challenge/data/device_activations_test.csv has 175 timesteps (hours) until now\n"
     ]
    }
   ],
   "source": [
    "val_features, val_labels, _, _ = read_and_preprocess_data(val_in_file, batch_size=1, device_list=device_list)\n",
    "test_features, test_labels, _, _ = read_and_preprocess_data(test_in_file, batch_size=1, device_list=device_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calculate ratio of positive to negative labels per device to adjust loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ratio of positive to negative outputs per device:  [0.08333333 0.24305556 0.165      0.2375     0.23277778 0.33444444\n",
      " 0.055     ]\n"
     ]
    }
   ],
   "source": [
    "def calc_ratio_positive_outputs_per_device(labels):\n",
    "    ratio_per_device = np.sum(labels, axis=0) / labels.shape[0]\n",
    "    print(\"Ratio of positive to negative outputs per device: \", ratio_per_device)\n",
    "    return np.array(ratio_per_device)\n",
    "ratio_positive_outputs_per_device = calc_ratio_positive_outputs_per_device(label_batch.reshape([-1, label_batch.shape[-1]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "USE_WEIGHTED_LOSS = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Weighted loss: Scales up loss for positive labels per-device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create our own weighted loss to combat label imbalance\n",
    "def weighted_loss(y_true, y_pred):\n",
    "    out = -(y_true * K.log(y_pred + 1e-5) / ratio_positive_outputs_per_device + (1.0 - y_true) * K.log(1.0 - y_pred + 1e-5))\n",
    "    return K.mean(out, axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(params):\n",
    "    \"\"\"\n",
    "    Creates an LSTM-based model given the parameters: 'lr', 'do', 'reg', 'lstm_units', 'n_outputs', 'n_features', 'use_weighted_loss'.\n",
    "    \"\"\"\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(params['lstm_units'], batch_input_shape=(params['batch_size'], None, params['n_features']), return_sequences=True, stateful=True, kernel_regularizer=l2(params['reg'])))\n",
    "    model.add(Dropout(params['dropout']))\n",
    "    model.add(Dense(params['n_outputs'], activation='sigmoid'))\n",
    "    \n",
    "    adam = optimizers.Adam(lr=params['lr'])\n",
    "    model.compile(loss=weighted_loss if params['use_weighted_loss'] else 'binary_crossentropy', optimizer=adam)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_24h(model, features, labels):\n",
    "    \"\"\"\n",
    "    Predicts a model's output for given features and the following 24 hours, reusing predictions as inputs\n",
    "    \"\"\"\n",
    "    \n",
    "    predictions = np.squeeze(model.predict(np.expand_dims(features, 0), batch_size=1))  # (n_timesteps, n_outputs)\n",
    "\n",
    "    all_predictions = []\n",
    "\n",
    "    last_features = np.squeeze(features)[-1]\n",
    "    last_predictions = tmp_prediction = predictions[-1]\n",
    "    tmp_features = np.array(last_features)\n",
    "    tmp_mean_occupancies = [mean_occupancies.loc[(tmp_features[0] * 24 + tmp_features[1], 'device_' + str(j + 1)), \n",
    "                                             'mean_occupancy'] for j in range(len(device_list))]\n",
    "    for i in range(24):\n",
    "\n",
    "        tmp_features = np.concatenate([tmp_features[:2], np.round(np.squeeze(tmp_prediction)), tmp_mean_occupancies])\n",
    "        \n",
    "        # Increment time features\n",
    "        if tmp_features[1] == 23:\n",
    "            tmp_features[0] = (tmp_features[0] + 1) % 7\n",
    "        tmp_features[1] = (tmp_features[1] + 1) % 24\n",
    "        \n",
    "        tmp_mean_occupancies = [mean_occupancies.loc[(tmp_features[0] * 24 + tmp_features[1], 'device_' + str(j + 1)), \n",
    "                                             'mean_occupancy'] for j in range(len(device_list))]\n",
    "        \n",
    "        tmp_prediction = np.round(model.predict(np.reshape(tmp_features, [1, 1, len(tmp_features)])))\n",
    "        \n",
    "        all_predictions += [tmp_prediction]\n",
    "\n",
    "    return np.concatenate(all_predictions)\n",
    "\n",
    "def calc_accuracy(model, params, test_X, test_Y):\n",
    "    \"\"\"\n",
    "    Calculates accuracy of a model on a test (or validation) set. Generates sub-sequences of the test set to test on.\n",
    "    The model gets i hours as inputs before having to predict the next 24 hours (i in range(48, n - 24) with \n",
    "    n = hours in test set). This gives more \"effective\" test set size than splitting the test set in non-overlapping\n",
    "    sequences. Depending on the real world scenario, the assumption of at least 48 hours of input might be relaxed/\n",
    "    strictened.\n",
    "    \"\"\"\n",
    "    # Hack around Keras batch size restriction (to have same for training/test)\n",
    "    model.save('tmp_model.h5')\n",
    "    test_params = dict(params)\n",
    "    test_params['batch_size'] = 1\n",
    "    test_model = create_model(test_params)\n",
    "    test_model.load_weights('tmp_model.h5')\n",
    "    os.remove('tmp_model.h5')\n",
    "    n = test_X.shape[1]\n",
    "    acc_accumulated = 0.0\n",
    "    for i in range(48, n - 24):\n",
    "        predictions = np.squeeze(predict_24h(test_model, test_X[0, :i], test_Y[0, :i]))\n",
    "        true_labels = test_Y[0, i:i+24]\n",
    "        \n",
    "        acc = np.sum(np.round(predictions) == true_labels) / predictions.size\n",
    "        acc_accumulated += acc\n",
    "    \n",
    "    return acc_accumulated / (n-72) # n-72 as we leave out 48 in the beginning and 24 at the end\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def train_model_with_params(params, train_X, train_Y):\n",
    "    model = create_model(params)\n",
    "    history = model.fit(train_X, train_Y, epochs=params['epochs'], batch_size=params['batch_size'], verbose=0, shuffle=False)\n",
    "    return model\n",
    "\n",
    "def eval_model_params(params, train_X, train_Y, val_X, val_Y):\n",
    "    \"\"\"\n",
    "    Trains and evaluates a model on a given validation set by calculating its accuracy on a 24h prediction basis as \n",
    "    described in calc_accuracy().\n",
    "    \"\"\"\n",
    "    model = train_model_with_params(params, train_X, train_Y)\n",
    "    val_acc = calc_accuracy(model, params, val_X, val_Y)\n",
    "    return model, val_acc\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameter (Grid) Search\n",
    "Usually I use the BayesianOptimization framework to efficiently calculate and evaluate hyperparameter spaces as GS\n",
    "gets out of hand quickly in terms of computational efficiency. In this case I simply ran out of time for that,\n",
    "so GS had to suffice. RS would have been an option, but I'm not too much of a fan and the training times in this \n",
    "project were \"ok\", so GS was my choice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# skip GS by default\n",
    "do_GS = False\n",
    "if do_GS:\n",
    "    gs_results = []\n",
    "    for do in [0.0, 0.2, 0.5]:\n",
    "        for units in [32, 64, 128, 256]:\n",
    "            for reg in [0.0, 0.01, 0.1]:\n",
    "                for n_epochs in [250]:\n",
    "                    for lr in [1e-3, 1e-4]:\n",
    "                        K.clear_session()\n",
    "                        tmp_params = {'lr': lr, \n",
    "                                       'use_weighted_loss': USE_WEIGHTED_LOSS,\n",
    "                                       'batch_size': BATCH_SIZE,\n",
    "                                       'dropout': do,\n",
    "                                       'epochs': n_epochs,\n",
    "                                       'n_outputs': len(device_list),\n",
    "                                       'n_features': feature_batch.shape[-1],\n",
    "                                       'lstm_units': units,\n",
    "                                       'devices': device_list,\n",
    "                                       'reg': reg}\n",
    "                        model, val_acc = eval_model_params(tmp_params, feature_batch, label_batch, val_features, val_labels)\n",
    "                        gs_results += [(val_acc, tmp_params)]\n",
    "                        print(\"Tmp result: \", val_acc, tmp_params)\n",
    "\n",
    "    for x in sorted(gs_results, key=lambda x: x[0], reverse=True):\n",
    "        print(\"Acc: {0}, params: {1}\".format(x[0], x[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train model with results from GS to evaluate\n",
    "Given the parameters from the grid search, evaluate also on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params = {'lr': 0.001, 'use_weighted_loss': True, 'batch_size': BATCH_SIZE, 'dropout': 0.0, 'epochs': 250, 'n_outputs': 7, 'n_features': 16, 'lstm_units': 128, 'devices': ['device_1', 'device_2', 'device_3', 'device_4', 'device_5', 'device_6', 'device_7'], 'reg': 0.0}\n",
    "K.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val acc for model 0.816832779623477\n"
     ]
    }
   ],
   "source": [
    "model, val_acc = eval_model_params(best_params, feature_batch, label_batch, val_features, val_labels)\n",
    "print(\"Val acc for model\", val_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test acc:  0.9211165048543685\n"
     ]
    }
   ],
   "source": [
    "test_acc = calc_accuracy(model, best_params, test_features, test_labels)\n",
    "print(\"Test acc: \", test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hours in data:  1014\n",
      "File challenge/data/device_activations_train.csv has 1013 timesteps (hours) until now\n"
     ]
    }
   ],
   "source": [
    "train_features, train_labels, _, _ = read_and_preprocess_data(in_file, batch_size=1, device_list=device_list, sequence_start_shift=20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train acc:  0.9620844086837648\n"
     ]
    }
   ],
   "source": [
    "train_acc = calc_accuracy(model, best_params, train_features, train_labels)\n",
    "print(\"Train acc: \", train_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving models and parameters\n",
    "Save the trained model to be reused in the inference/server script."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_occupancies.to_pickle('mean_occupancy.pkl')\n",
    "\n",
    "model.save('model.h5')\n",
    "import json\n",
    "\n",
    "with open('params.json', 'w', encoding='utf-8') as fp:\n",
    "    json.dump(best_params, fp)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
